<<<<<<< HEAD
import logging
import os
KNOWLEDGE_BASE_INFO=(
	"ä½ å·²ç»è¿›å…¥çŸ¥è¯†åº“æ¨¡å¼,å¯ä»¥ä½¿ç”¨æˆ‘ä»¬ç›®å‰å·²ç»çŽ°æœ‰çš„çŸ¥è¯†åº“ï¼Œä¹Ÿå¯ä»¥æ–°å»ºçŸ¥è¯†åº“"
)
WEB_TITLE="""
#ðŸŽ‰ðŸ¤ŸðŸŽˆè¿™é‡Œæ˜¯åŸºäºŽlangchainå®žçŽ°çš„æ™ºèƒ½å®¢æœæœºå™¨äººï¼Œæˆ‘çš„é»˜è®¤æ¨¡åž‹æ˜¯ChatGLM-6B
"""
LOAD_IN_8BIT = False
LLM_DEVICE = "cuda"
LLM_MODEL = "chatglm-6b"
LLM_HISTORY_LEN=1
VECTOR_SEARCH_TOP_K=3
CHUNK_SIZE=200   #åŒ¹é…å•æ®µä¸Šä¸‹æ–‡çš„é•¿åº¦
VECTOR_SEARCH_SCORE_THRESHOLD=5  #æ•°æ®åº“çš„åŒ¹é…ç›¸ä¼¼åº¦ï¼Œä¸º0ä¸ç”Ÿæ•ˆï¼Œè¿™ä¸ªå€¼ä¸ç¡®å®š
SENTENCE_SIZE=20
STREAME=True
ROOT_PATH=os.path.join(os.path.dirname(os.path.dirname(__file__)), "knowledge_base")
REPLY_WITH_SOURCE_SOCRE=True
REPLY_WITH_SCORE=False
LOG_FORMAT = "%(levelname) -5s %(asctime)s" "-1d: %(message)s"
logger=logging.getLogger()
logger.setLevel(logging.INFO)
logging.basicConfig(format=LOG_FORMAT)
PROMPT_TEMPLATE="""å·²çŸ¥ä¿¡æ¯ï¼š{context}\t\té—®é¢˜ï¼š{question}è¯·æ³¨æ„ï¼Œå›žç­”å¿…é¡»ç®€æ´æ˜Žäº†ã€ä¸“ä¸šå‡†ç¡®ï¼Œä»…åŸºäºŽå·²çŸ¥ä¿¡æ¯æä¾›ç­”æ¡ˆã€‚å¦‚æžœé—®é¢˜ä¸æ˜Žç¡®æˆ–æ— æ³•ä»Žå·²çŸ¥ä¿¡æ¯ä¸­å¾—åˆ°ç­”æ¡ˆï¼Œåº”å›žå¤"æ ¹æ®å·²çŸ¥ä¿¡æ¯æ— æ³•å›žç­”è¯¥é—®é¢˜ï¼Œè¯·æä¾›è¶³å¤Ÿçš„æœ¬åœ°çŸ¥è¯†åº“ä¿¡æ¯"ã€‚åŒæ—¶ï¼Œè¯·å‹¿åœ¨å›žç­”ä¸­ç¼–é€ ä¿¡æ¯æˆ–è¶…å‡ºå·²çŸ¥ä¿¡æ¯èŒƒå›´å›žç­”é—®é¢˜ã€‚ç­”æ¡ˆè¯·ä½¿ç”¨ä¸­æ–‡ã€‚"""
# PROMPT_TEMPLATE="""å·²çŸ¥é—®é¢˜ï¼š{question}è¯·å…ˆåˆ¤æ–­è¯¥é—®é¢˜æ˜¯ä¸æ˜¯é—®é¢˜ï¼Œå¦‚æžœä¸æ˜¯ï¼Œè¯·è¯´â€è¯·æ˜Žç¡®ä½ çš„é—®é¢˜â€œã€‚å¦‚æžœæ˜¯ï¼Œæ ¹æ®ä»¥ä¸‹å·²çŸ¥ä¿¡æ¯ï¼Œç®€æ´ä¸”ä¸“ä¸šåœ°å›žå¤ç”¨æˆ·ä¿¡æ¯ï¼Œå¦‚æžœæ— æ³•ä»Žå·²çŸ¥ä¿¡æ¯ä¸­å¾—åˆ°ç­”æ¡ˆï¼Œè¯·å›žå¤è¯·æä¾›è¶³å¤Ÿçš„çŸ¥è¯†ï¼Œåˆ‡å‹¿åœ¨ç­”æ¡ˆä¸­èƒ¡ç¼–ä¹±é€ ï¼Œåˆ‡å‹¿åœ¨ç­”æ¡ˆä¸­å›žå¤ä¸Žå·²çŸ¥ä¿¡æ¯æ— å…³çš„å†…å®¹ï¼Œå·²çŸ¥ä¿¡æ¯æ˜¯{context}"""
ACCESS_HUGGING_TOKEN="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"
llm_model_dict = {
	"chatglm-6b-int8": {
		"name": "chatglm-6b-int8",
		"pretrained_model_name": "THUDM/chatglm-6b-int8",
		"local_model_path": None,
		"provides": "ChatGLM"
	},
	"chatglm-6b": {
		"name": "chatglm-6b",
		"pretrained_model_name": "THUDM/chatglm-6b",
		"local_model_path": None,
		"provides": "ChatGLM"
	},

	"moss": {
		"name": "moss",
		"pretrained_model_name": "fnlp/moss-moon-003-sft",
		"local_model_path": None,
		"provides": "MOSSLLM"
	},

}


# åœ¨ä»¥ä¸‹å­—å…¸ä¸­ä¿®æ”¹å±žæ€§å€¼ï¼Œä»¥æŒ‡å®šæœ¬åœ°embeddingæ¨¡åž‹å­˜å‚¨ä½ç½®
# å¦‚å°† "text2vec": "GanymedeNil/text2vec-large-chinese" ä¿®æ”¹ä¸º "text2vec": "User/Downloads/text2vec-large-chinese"
# æ­¤å¤„è¯·å†™ç»å¯¹è·¯å¾„
embedding_model_dict = {
    "text2vec-base": "shibing624/text2vec-base-chinese",
    "text2vec": "GanymedeNil/text2vec-large-chinese",
}
=======
import os

import torch

# device config
EMBEDDING_DEVICE = "cuda" if torch.cuda.is_available(
) else "mps" if torch.backends.mps.is_available() else "cpu"
LLM_DEVICE = "cuda" if torch.cuda.is_available(
) else "mps" if torch.backends.mps.is_available() else "cpu"
num_gpus = torch.cuda.device_count()

# model cache config
MODEL_CACHE_PATH = os.path.join(os.path.dirname(__file__), 'model_cache')


# vector storage config
VECTOR_STORE_PATH='./vector_store'
COLLECTION_NAME='my_collection'


# init model config
init_llm = "ChatGLM-6B-int8"
init_embedding_model = "text2vec-base"

# model config
embedding_model_dict = {
    "ernie-tiny": "nghuyong/ernie-3.0-nano-zh",
    "ernie-base": "nghuyong/ernie-3.0-base-zh",
    "ernie-medium": "nghuyong/ernie-3.0-medium-zh",
    "ernie-xbase": "nghuyong/ernie-3.0-xbase-zh",
    "text2vec-base": "GanymedeNil/text2vec-base-chinese",
    'simbert-base-chinese': 'WangZeJun/simbert-base-chinese',
    'paraphrase-multilingual-MiniLM-L12-v2': "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
}


llm_model_dict = {
    "chatglm": {
        "ChatGLM-6B": "THUDM/chatglm-6b",
        "ChatGLM-6B-int4": "THUDM/chatglm-6b-int4",
        "ChatGLM-6B-int8": "THUDM/chatglm-6b-int8",
        "ChatGLM-6b-int4-qe": "THUDM/chatglm-6b-int4-qe"
    },
    "belle": {
        "BELLE-LLaMA-Local": "/pretrainmodel/belle",
    },
    "vicuna": {
        "Vicuna-Local": "/pretrainmodel/vicuna",
    }
}
>>>>>>> 33ec2a55e31a7a49367b754399c8ddfe9750a4e2
