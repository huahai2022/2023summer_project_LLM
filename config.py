import logging
import os
KNOWLEDGE_BASE_INFO=(
	"ä½ å·²ç»è¿›å…¥çŸ¥è¯†åº“æ¨¡å¼,å¯ä»¥ä½¿ç”¨æˆ‘ä»¬ç›®å‰å·²ç»ç°æœ‰çš„çŸ¥è¯†åº“ï¼Œä¹Ÿå¯ä»¥æ–°å»ºçŸ¥è¯†åº“"
)
WEB_TITLE="""
#ğŸ‰ğŸ¤ŸğŸˆè¿™é‡Œæ˜¯åŸºäºlangchainå®ç°çš„æ™ºèƒ½å®¢æœæœºå™¨äººï¼Œæˆ‘çš„é»˜è®¤æ¨¡å‹æ˜¯ChatGLM-6B
"""
LOAD_IN_8BIT = False
LLM_DEVICE = "cuda"
LLM_MODEL = "chatglm-6b"
LLM_HISTORY_LEN=1
VECTOR_SEARCH_TOP_K=2
CHUNK_SIZE=200   #åŒ¹é…å•æ®µä¸Šä¸‹æ–‡çš„é•¿åº¦
VECTOR_SEARCH_SCORE_THRESHOLD=0  #æ•°æ®åº“çš„åŒ¹é…ç›¸ä¼¼åº¦ï¼Œä¸º0ä¸ç”Ÿæ•ˆï¼Œè¿™ä¸ªå€¼ä¸ç¡®å®š
SENTENCE_SIZE=20
STREAME=False
ROOT_PATH=os.path.join(os.path.dirname(os.path.dirname(__file__)), "knowledge_base")
REPLY_WITH_SOURCE_SOCRE=True
REPLY_WITH_SCORE=False
LOG_FORMAT = "%(levelname) -5s %(asctime)s" "-1d: %(message)s"
logger=logging.getLogger()
logger.setLevel(logging.INFO)
logging.basicConfig(format=LOG_FORMAT)
PROMPT_TEMPLATE="""å·²çŸ¥ä¿¡æ¯ï¼š{context}
æ ¹æ®ä¸Šè¿°å·²çŸ¥ä¿¡æ¯ï¼Œç®€æ´ä¸”ä¸“ä¸šåœ°å›ç­”ç”¨æˆ·åœ°é—®é¢˜ã€‚å¦‚æœé—®é¢˜ä¸æ¸…æ™°æˆ–æ— æ³•ä»å·²çŸ¥ä¿¡æ¯ä¸­å¾—åˆ°ç­”æ¡ˆï¼Œè¯·å›å¤"æ ¹æ®å·²çŸ¥ä¿¡æ¯æ— æ³•å›ç­”è¯¥é—®é¢˜ï¼Œè¯·æä¾›è¶³å¤Ÿçš„æœ¬åœ°çŸ¥è¯†åº“ä¿¡æ¯"ï¼Œåˆ‡å‹¿åœ¨ç­”æ¡ˆä¸­èƒ¡ç¼–ä¹±é€ ï¼Œåˆ‡å‹¿å›ç­”å·²çŸ¥ä¿¡æ¯ä»¥å¤–çš„é—®é¢˜ï¼Œé—®é¢˜ä¸æ˜ç¡®çš„æ—¶ï¼Œè¯·å›ç­”é—®é¢˜ä¸æ˜ç¡®ï¼Œç­”æ¡ˆè¯·ä½¿ç”¨ä¸­æ–‡ã€‚é—®é¢˜æ˜¯ï¼š{question}"""
# PROMPT_TEMPLATE="""å·²çŸ¥é—®é¢˜ï¼š{question}è¯·å…ˆåˆ¤æ–­è¯¥é—®é¢˜æ˜¯ä¸æ˜¯é—®é¢˜ï¼Œå¦‚æœä¸æ˜¯ï¼Œè¯·è¯´â€è¯·æ˜ç¡®ä½ çš„é—®é¢˜â€œã€‚å¦‚æœæ˜¯ï¼Œæ ¹æ®ä»¥ä¸‹å·²çŸ¥ä¿¡æ¯ï¼Œç®€æ´ä¸”ä¸“ä¸šåœ°å›å¤ç”¨æˆ·ä¿¡æ¯ï¼Œå¦‚æœæ— æ³•ä»å·²çŸ¥ä¿¡æ¯ä¸­å¾—åˆ°ç­”æ¡ˆï¼Œè¯·å›å¤è¯·æä¾›è¶³å¤Ÿçš„çŸ¥è¯†ï¼Œåˆ‡å‹¿åœ¨ç­”æ¡ˆä¸­èƒ¡ç¼–ä¹±é€ ï¼Œåˆ‡å‹¿åœ¨ç­”æ¡ˆä¸­å›å¤ä¸å·²çŸ¥ä¿¡æ¯æ— å…³çš„å†…å®¹ï¼Œå·²çŸ¥ä¿¡æ¯æ˜¯{context}"""
ACCESS_HUGGING_TOKEN="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"
llm_model_dict = {
	"chatglm-6b-int4-qe": {
		"name": "chatglm-6b-int4-qe",
		"pretrained_model_name": "THUDM/chatglm-6b-int4-qe",
		"local_model_path": None,
		"provides": "ChatGLM"
	},
	"chatglm-6b-int4": {
		"name": "chatglm-6b-int4",
		"pretrained_model_name": "THUDM/chatglm-6b-int4",
		"local_model_path": None,
		"provides": "ChatGLM"
	},
	"chatglm-6b-int8": {
		"name": "chatglm-6b-int8",
		"pretrained_model_name": "THUDM/chatglm-6b-int8",
		"local_model_path": None,
		"provides": "ChatGLM"
	},
	"chatglm-6b": {
		"name": "chatglm-6b",
		"pretrained_model_name": "THUDM/chatglm-6b",
		"local_model_path": None,
		"provides": "ChatGLM"
	},

	"chatyuan": {
		"name": "chatyuan",
		"pretrained_model_name": "ClueAI/ChatYuan-large-v2",
		"local_model_path": None,
		"provides": None
	},
	"moss": {
		"name": "moss",
		"pretrained_model_name": "fnlp/moss-moon-003-sft",
		"local_model_path": None,
		"provides": "MOSSLLM"
	},
	"vicuna-13b-hf": {
		"name": "vicuna-13b-hf",
		"pretrained_model_name": "vicuna-13b-hf",
		"local_model_path": None,
		"provides": "LLamaLLM"
	},

	# é€šè¿‡ fastchat è°ƒç”¨çš„æ¨¡å‹è¯·å‚è€ƒå¦‚ä¸‹æ ¼å¼
	"fastchat-chatglm-6b": {
		"name": "chatglm-6b",  # "name"ä¿®æ”¹ä¸ºfastchatæœåŠ¡ä¸­çš„"model_name"
		"pretrained_model_name": "chatglm-6b",
		"local_model_path": None,
		"provides": "FastChatOpenAILLM",  # ä½¿ç”¨fastchat apiæ—¶ï¼Œéœ€ä¿è¯"provides"ä¸º"FastChatOpenAILLM"
		"api_base_url": "http://localhost:8000/v1"  # "name"ä¿®æ”¹ä¸ºfastchatæœåŠ¡ä¸­çš„"api_base_url"
	},

	# é€šè¿‡ fastchat è°ƒç”¨çš„æ¨¡å‹è¯·å‚è€ƒå¦‚ä¸‹æ ¼å¼
	"fastchat-vicuna-13b-hf": {
		"name": "vicuna-13b-hf",  # "name"ä¿®æ”¹ä¸ºfastchatæœåŠ¡ä¸­çš„"model_name"
		"pretrained_model_name": "vicuna-13b-hf",
		"local_model_path": None,
		"provides": "FastChatOpenAILLM",  # ä½¿ç”¨fastchat apiæ—¶ï¼Œéœ€ä¿è¯"provides"ä¸º"FastChatOpenAILLM"
		"api_base_url": "http://localhost:8000/v1"  # "name"ä¿®æ”¹ä¸ºfastchatæœåŠ¡ä¸­çš„"api_base_url"
	},
}


# åœ¨ä»¥ä¸‹å­—å…¸ä¸­ä¿®æ”¹å±æ€§å€¼ï¼Œä»¥æŒ‡å®šæœ¬åœ°embeddingæ¨¡å‹å­˜å‚¨ä½ç½®
# å¦‚å°† "text2vec": "GanymedeNil/text2vec-large-chinese" ä¿®æ”¹ä¸º "text2vec": "User/Downloads/text2vec-large-chinese"
# æ­¤å¤„è¯·å†™ç»å¯¹è·¯å¾„
embedding_model_dict = {
    "ernie-tiny": "nghuyong/ernie-3.0-nano-zh",
    "ernie-base": "nghuyong/ernie-3.0-base-zh",
    "text2vec-base": "shibing624/text2vec-base-chinese",
    "text2vec": "GanymedeNil/text2vec-large-chinese",
    "m3e-small": "moka-ai/m3e-small",
    "m3e-base": "moka-ai/m3e-base",
}
